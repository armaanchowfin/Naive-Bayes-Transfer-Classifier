{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_3biNuMpEYF"
      },
      "source": [
        "# Group - 9\n",
        "## Naive Bayes Transfer Classifier\n"
      ],
      "id": "A_3biNuMpEYF"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l0U6HBEzpCfd"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import string\n",
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import model_selection\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report"
      ],
      "id": "l0U6HBEzpCfd"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4giUdnJMpOnU"
      },
      "source": [
        "### Splitting Data into test and train sets using 20newsgroups dataset. (we are only using a small set from the original dataset)."
      ],
      "id": "4giUdnJMpOnU"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_VNTZENgpCfi"
      },
      "outputs": [],
      "source": [
        "# A = rec, A1 = comp.windows.x, A2 = rec.sport.hockey -> class 0\n",
        "# B = talk, B1 = talk.politics.guns, B2 = talk.politics.mideast -> class 1\n",
        "\n",
        "X_Train = [] \n",
        "Y_Train = [] \n",
        "\n",
        "for doc in os.listdir('mini_newsgroups/rec.sport.baseball'):\n",
        "  with open('mini_newsgroups/rec.sport.baseball/'+doc, \"r\") as f: \n",
        "            X_Train.append((doc,f.read()))\n",
        "            Y_Train.append('rec')\n",
        "\n",
        "for doc in os.listdir('mini_newsgroups/talk.politics.guns'):\n",
        "  with open('mini_newsgroups/talk.politics.guns/'+doc, \"r\") as f: \n",
        "            X_Train.append((doc,f.read()))\n",
        "            Y_Train.append('talk')\n",
        "\n",
        "num_classes = 2           "
      ],
      "id": "_VNTZENgpCfi"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zgrDOUdNpCfj"
      },
      "outputs": [],
      "source": [
        "X_Test = [] \n",
        "Y_Test = [] \n",
        "for doc in os.listdir('mini_newsgroups/rec.sport.hockey'):\n",
        "  with open('mini_newsgroups/rec.sport.hockey/'+doc, \"r\") as f:\n",
        "            X_Test.append((doc,f.read()))\n",
        "            Y_Test.append('rec')\n",
        "\n",
        "for doc in os.listdir('mini_newsgroups/talk.politics.mideast'):\n",
        "  with open('mini_newsgroups/talk.politics.mideast/'+doc, \"r\") as f:\n",
        "            X_Test.append((doc,f.read()))\n",
        "            Y_Test.append('talk')\n",
        "\n",
        "num_classes = 2     "
      ],
      "id": "zgrDOUdNpCfj"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Choosing features"
      ],
      "metadata": {
        "id": "774agTq9svbV"
      },
      "id": "774agTq9svbV"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9hJ_fEVopCfj"
      },
      "outputs": [],
      "source": [
        "# A list of common english words which should not affect predictions\n",
        "stopwords = ['a', 'about', 'above', 'across', 'after', 'afterwards', 'again', 'against', 'all', 'almost', 'alone',\n",
        "             'along', 'already', 'also', 'although', 'always', 'am', 'among', 'amongst', 'amoungst', 'amount',\n",
        "             'an', 'and', 'another', 'any', 'anyhow', 'anyone', 'anything', 'anyway', 'anywhere', 'are', 'around',\n",
        "             'as', 'at', 'back', 'be', 'became', 'because', 'become', 'becomes', 'becoming', 'been', 'before',\n",
        "             'beforehand', 'behind', 'being', 'below', 'beside', 'besides', 'between', 'beyond', 'bill', 'both',\n",
        "             'bottom', 'but', 'by', 'call', 'can', 'cannot', 'cant', 'co', 'con', 'could', 'couldnt', 'cry', 'de',\n",
        "             'describe', 'detail', 'did', 'do', 'does', 'doing', 'don', 'done', 'down', 'due', 'during', 'each', 'eg',\n",
        "             'eight', 'either', 'eleven', 'else', 'elsewhere', 'empty', 'enough', 'etc', 'even', 'ever', 'every', 'everyone',\n",
        "             'everything', 'everywhere', 'except', 'few', 'fifteen', 'fify', 'fill', 'find', 'fire', 'first', 'five', 'for',\n",
        "             'former', 'formerly', 'forty', 'found', 'four', 'from', 'front', 'full', 'further', 'get', 'give', 'go', 'had',\n",
        "             'has', 'hasnt', 'have', 'having', 'he', 'hence', 'her', 'here', 'hereafter', 'hereby', 'herein', 'hereupon',\n",
        "             'hers', 'herself', 'him', 'himself', 'his', 'how', 'however', 'hundred', 'i', 'ie', 'if', 'in', 'inc', 'indeed',\n",
        "             'interest', 'into', 'is', 'it', 'its', 'itself', 'just', 'keep', 'last', 'latter', 'latterly', 'least', 'less',\n",
        "             'ltd', 'made', 'many', 'may', 'me', 'meanwhile', 'might', 'mill', 'mine', 'more', 'moreover', 'most', 'mostly',\n",
        "             'move', 'much', 'must', 'my', 'myself', 'name', 'namely', 'neither', 'never', 'nevertheless', 'next', 'nine',\n",
        "             'no', 'nobody', 'none', 'noone', 'nor', 'not', 'nothing', 'now', 'nowhere', 'of', 'off', 'often', 'on', 'once',\n",
        "             'one', 'only', 'onto', 'or', 'other', 'others', 'otherwise', 'our', 'ours', 'ourselves', 'out', 'over', 'own',\n",
        "             'part', 'per', 'perhaps', 'please', 'put', 'rather', 're', 's', 'same', 'see', 'seem', 'seemed', 'seeming',\n",
        "             'seems', 'serious', 'several', 'she', 'should', 'show', 'side', 'since', 'sincere', 'six', 'sixty', 'so', \n",
        "             'some', 'somehow', 'someone', 'something', 'sometime', 'sometimes', 'somewhere', 'still', 'such', 'system',\n",
        "             't', 'take', 'ten', 'than', 'that', 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'thence', 'there',\n",
        "             'thereafter', 'thereby', 'therefore', 'therein', 'thereupon', 'these', 'they', 'thickv', 'thin', 'third', 'this',\n",
        "             'those', 'though', 'three', 'through', 'throughout', 'thru', 'thus', 'to', 'together', 'too', 'top', 'toward',\n",
        "             'towards', 'twelve', 'twenty', 'two', 'un', 'under', 'until', 'up', 'upon', 'us', 'very', 'via', 'was', 'we',\n",
        "             'well', 'were', 'what', 'whatever', 'when', 'whence', 'whenever', 'where', 'whereafter', 'whereas', 'whereby',\n",
        "             'wherein', 'whereupon', 'wherever', 'whether', 'which', 'while', 'whither', 'who', 'whoever', 'whole', 'whom',\n",
        "             'whose', 'why', 'will', 'with', 'within', 'without', 'would', 'yet', 'you', 'your', 'yours', 'yourself',\n",
        "             'yourselves']"
      ],
      "id": "9hJ_fEVopCfj"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aW2SP6z5pCfl"
      },
      "outputs": [],
      "source": [
        "# Building a vocabulary of words from the given documents\n",
        "vocab = {}    #dictionary with unique words (key) and their freq (value)\n",
        "for i in range(len(X_Train)):   #ith document\n",
        "    word_list = []\n",
        "    for word in X_Train[i][1].split():   #X_train[i][0] has file no.\n",
        "        word_new  = word.strip(string.punctuation).lower()   #strip(..) removes punctuation characters from beginning and end\n",
        "        if (len(word_new)>2)  and (word_new not in stopwords):  \n",
        "            if word_new in vocab:\n",
        "                vocab[word_new]+=1\n",
        "            else:\n",
        "                vocab[word_new]=1            "
      ],
      "id": "aW2SP6z5pCfl"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KGAg3SNGpCfm",
        "outputId": "ab2356cb-cca1-4dc8-f95f-4aff921df35f"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Plotting a graph of no of words with a given frequency to decide cutoff drequency\n",
        "\n",
        "num_words = [0 for i in range(max(vocab.values())+1)]  # i goes till it covers all frequenicies till most freq word, num_words is a list of all possible freq\n",
        "freq = [i for i in range(max(vocab.values())+1)]       # x axis\n",
        "total_words = 0\n",
        "\n",
        "for key in vocab:\n",
        "    num_words[vocab[key]]+=1  # num_words[with this freq] = ? how much\n",
        "    \n",
        "for i in range (len(num_words)):\n",
        "    total_words += num_words[i]\n",
        "plt.plot(freq,num_words)\n",
        "plt.axis([1, 10, 0, 20000])\n",
        "plt.xlabel(\"Frequency\")\n",
        "plt.ylabel(\"No of words\")  #no of words with each freq\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "id": "KGAg3SNGpCfm"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ooUCz3eypCfn",
        "outputId": "f070a9b8-9856-467e-f11e-b6032d7a7b91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of words with frequency higher than cutoff frequency(150) : 13\n"
          ]
        }
      ],
      "source": [
        "cutoff_freq = 150\n",
        "# For deciding cutoff frequency\n",
        "num_words_above_cutoff = len(vocab)-sum(num_words[0:cutoff_freq]) \n",
        "print(\"Number of words with frequency higher than cutoff frequency({}) :\".format(cutoff_freq),num_words_above_cutoff)"
      ],
      "id": "ooUCz3eypCfn"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AcDCdC15pCfn"
      },
      "outputs": [],
      "source": [
        "# Words with frequency higher than cutoff frequency are chosen as features\n",
        "# (i.e we remove words with low frequencies as they would not be significant )\n",
        "features = []\n",
        "for key in vocab:\n",
        "    if vocab[key] >=cutoff_freq:\n",
        "        features.append(key)"
      ],
      "id": "AcDCdC15pCfn"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zi2HHocJpCfo",
        "outputId": "6fa2e51e-da69-46bc-e64d-e8d2cf781d52"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['path',\n",
              " 'newsgroups',\n",
              " 'subject',\n",
              " 'message-id',\n",
              " 'date',\n",
              " 'apr',\n",
              " 'references',\n",
              " 'organization',\n",
              " 'lines',\n",
              " 'article',\n",
              " 'writes',\n",
              " '1993',\n",
              " 'gmt']"
            ]
          },
          "execution_count": 108,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "features"
      ],
      "id": "zi2HHocJpCfo"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-dSulz3tpCfp"
      },
      "outputs": [],
      "source": [
        "X_train = np.zeros((len(X_Train),len(features)))\n",
        "for i in range(len(X_Train)):\n",
        "    word_list = [ word.strip(string.punctuation).lower() for word in X_Train[i][1].split()]\n",
        "    for word in word_list:\n",
        "        if word in features:\n",
        "            X_train[i][features.index(word)] += 1\n",
        "\n",
        "X_test = np.zeros((len(X_Test),len(features)))\n",
        "for i in range(len(X_Test)):\n",
        "    word_list = [ word.strip(string.punctuation).lower() for word in X_Test[i][1].split()]\n",
        "    for word in word_list:\n",
        "        if word in features:\n",
        "            X_test[i][features.index(word)] += 1\n",
        "\n",
        "Y_train = np.zeros(len(Y_Train))\n",
        "for i in range(len(Y_Train)):\n",
        "    if(Y_Train[i].find(\"talk\")):\n",
        "        Y_train[i] = 1\n",
        "        \n",
        "Y_test = np.zeros(len(Y_Test))\n",
        "for i in range(len(Y_Test)):\n",
        "    if(Y_Test[i].find(\"talk\")):\n",
        "        Y_test[i] = 1"
      ],
      "id": "-dSulz3tpCfp"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Algorithm - 1"
      ],
      "metadata": {
        "id": "ReNgMhdbtMz2"
      },
      "id": "ReNgMhdbtMz2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oJFSvgmupCfq"
      },
      "outputs": [],
      "source": [
        "def NTBCAlgorithm(T, p_dl, p_du):\n",
        "    # Number of iterations T\n",
        "    # Finding p_c|d\n",
        "    label1 = 0\n",
        "    for i in range(len(Y_train)):\n",
        "        if Y_train[i] == 1:\n",
        "            label1+=1\n",
        "            \n",
        "    # initializations\n",
        "    p_cd = np.zeros((2, len(X_train)))\n",
        "    p_wc = np.zeros((2, len(features)))\n",
        "    p_c = np.zeros((2))\n",
        "    p_d = np.zeros((len(X_train))) \n",
        "    p_c_Du = np.zeros((2))\n",
        "    p_c_Dl = np.zeros((2))\n",
        "    \n",
        "    n_w_c_Dl = np.zeros((len(features), 2))\n",
        "    n_w_c_Du = np.zeros((len(features), 2))\n",
        "    \n",
        "    n_c_Dl = np.zeros((2))\n",
        "    n_c_Du = np.zeros((2))\n",
        "    \n",
        "    p_wc_Dl = np.zeros((len(features), 2))\n",
        "    p_wc_Du = np.zeros((len(features), 2))\n",
        "    \n",
        "    p_Du = np.asarray([])\n",
        "    \n",
        "    p_Dl = np.asarray([])\n",
        "    p_c[1] = label1/len(Y_train_dataset)\n",
        "    p_c[0] = 1-p_c[1]\n",
        "    n_w_c = np.zeros((len(features), 2))\n",
        "    nC = np.zeros((2))\n",
        "    \n",
        "    for w in range(len(features)):\n",
        "        for c in range(num_classes):\n",
        "            for d in range(len(X_test)):\n",
        "                if(Y_test[d] == c):\n",
        "                    n_w_c[w][c] += X_test[d][w]\n",
        "                    nC[c] += 1\n",
        "\n",
        "    for c in range(num_classes):\n",
        "        for w in range(len(features)):\n",
        "            p_wc[c][w] = (1+n_w_c[w][c])/(len(features)+nC[c])\n",
        "\n",
        "\n",
        "    #start of algorithm\n",
        "    for t in range(1,T+1):\n",
        "        \n",
        "        # Equation 6\n",
        "        for c in range(num_classes):\n",
        "            for d in range(len(X_test)):\n",
        "                temp = p_c[c]\n",
        "                for w in range(len(X_test[d])):\n",
        "                    if(Y_test[d] == c):\n",
        "                        temp *= pow(p_wc[c][w], X_test[d][w])\n",
        "                p_cd[c][d] = temp\n",
        "                \n",
        "        # Equation 7\n",
        "        for c in range(num_classes):             \n",
        "            for c in range (num_classes):\n",
        "                for d in range (len(X_train)):\n",
        "                    p_c_Du[c] += p_cd[c][d]*(1/len(X_train))\n",
        "\n",
        "                for d in range (len(X_test)):\n",
        "                    p_c_Dl[c] += p_cd[c][d]*(1/len(X_test))\n",
        "            p_c[c] = p_du*p_c_Du[c] + p_dl*p_c_Dl[c]\n",
        "            \n",
        "            for w in range(len(features)):\n",
        "                for c in range(num_classes):\n",
        "                    for d in range(len(X_train)):\n",
        "                        n_w_c_Dl[w][c] += X_train[d][w]*p_cd[c][d]\n",
        "                    for d in range(len(X_test)):\n",
        "                        n_w_c_Du[w][c] += X_test[d][w]*p_cd[c][d]\n",
        "\n",
        "            for d in range (len(X_train)):\n",
        "                n_c_Dl[c] += np.sum(X_train[d])*p_cd[c][d]\n",
        "\n",
        "            for d in range (len(X_test)):\n",
        "                n_c_Du[c] += np.sum(X_train[d])*p_cd[c][d]\n",
        "\n",
        "            for w in range(len(features)):\n",
        "                for c in range(num_classes):\n",
        "                    p_wc_Dl[w][c] = (1+n_w_c_Dl[w][c])/(len(features)+n_c_Dl[c])\n",
        "                    p_wc_Du[w][c] = (1+n_w_c_Du[w][c])/(len(features)+n_c_Du[c])\n",
        "\n",
        "            for w in range(len(features)):\n",
        "                p_wc[c][w] = p_du*p_c_Du[c]*p_wc_Du[w][c] + p_dl*p_c_Dl[c]*p_wc_Dl[w][c]\n",
        "\n",
        "    return p_cd"
      ],
      "id": "oJFSvgmupCfq"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### KL- Divergence"
      ],
      "metadata": {
        "id": "ee_B2jw7tQYU"
      },
      "id": "ee_B2jw7tQYU"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qYw64rPnpCfr"
      },
      "outputs": [],
      "source": [
        "from scipy.special import rel_entr\n",
        "\n",
        "def KL_Divergence(dist1, dist2):\n",
        "    return sum(rel_entr(dist1, dist2))"
      ],
      "id": "qYw64rPnpCfr"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Finding Probability Distributions"
      ],
      "metadata": {
        "id": "DpKMu_1jtTDj"
      },
      "id": "DpKMu_1jtTDj"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h9HQWtxdpCfr"
      },
      "outputs": [],
      "source": [
        "# Finding Probability distribution of Labelled set and Unlabelled set\n",
        "\n",
        "def prob_dist(data):\n",
        "    probabilities = []\n",
        "    sumt= 0\n",
        "    for i in range(len(data[0])):\n",
        "        count = 0\n",
        "        for j in range(len(data)):\n",
        "            count += data[j][i]\n",
        "        probabilities.append(count)\n",
        "\n",
        "    for i in range(len(probabilities)):\n",
        "        sumt += probabilities[i]\n",
        "\n",
        "    probabilities = probabilities/sumt\n",
        "\n",
        "    return probabilities"
      ],
      "id": "h9HQWtxdpCfr"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Algorithm - 2"
      ],
      "metadata": {
        "id": "LsUB9yMdtXuV"
      },
      "id": "LsUB9yMdtXuV"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qYKzAykppCfs"
      },
      "outputs": [],
      "source": [
        "def NTBCwithAutomaticParameterSetting():\n",
        "    dist1  = prob_dist(X_train)\n",
        "    dist2 = prob_dist(X_test)\n",
        "    kl_div = KL_Divergence(dist1, dist2)\n",
        "    gamma = 0.042*(math.pow(kl_div, -2.276))\n",
        "    p_Dl = np.float64(gamma/(1+gamma))\n",
        "    p_Du = 1 - p_Dl\n",
        "    return NTBCAlgorithm(3, p_Dl, p_Du)"
      ],
      "id": "qYKzAykppCfs"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BIoXiu-kpCfs",
        "outputId": "fe604f38-f1a9-41e2-e689-f26229704d3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[5.00000000e-01 5.00000000e-01 5.00000000e-01 5.00000000e-01\n",
            "  5.00000000e-01 5.00000000e-01 5.00000000e-01 5.00000000e-01\n",
            "  5.00000000e-01 5.00000000e-01 5.00000000e-01 5.00000000e-01\n",
            "  5.00000000e-01 5.00000000e-01 5.00000000e-01 5.00000000e-01\n",
            "  5.00000000e-01 5.00000000e-01 5.00000000e-01 5.00000000e-01\n",
            "  5.00000000e-01 5.00000000e-01 5.00000000e-01 5.00000000e-01\n",
            "  5.00000000e-01 5.00000000e-01 5.00000000e-01 5.00000000e-01\n",
            "  5.00000000e-01 5.00000000e-01 5.00000000e-01 5.00000000e-01\n",
            "  5.00000000e-01 5.00000000e-01 5.00000000e-01 5.00000000e-01\n",
            "  5.00000000e-01 5.00000000e-01 5.00000000e-01 5.00000000e-01\n",
            "  5.00000000e-01 5.00000000e-01 5.00000000e-01 5.00000000e-01\n",
            "  5.00000000e-01 5.00000000e-01 5.00000000e-01 5.00000000e-01\n",
            "  5.00000000e-01 5.00000000e-01 5.00000000e-01 5.00000000e-01\n",
            "  5.00000000e-01 5.00000000e-01 5.00000000e-01 5.00000000e-01\n",
            "  5.00000000e-01 5.00000000e-01 5.00000000e-01 5.00000000e-01\n",
            "  5.00000000e-01 5.00000000e-01 5.00000000e-01 5.00000000e-01\n",
            "  5.00000000e-01 5.00000000e-01 5.00000000e-01 5.00000000e-01\n",
            "  5.00000000e-01 5.00000000e-01 5.00000000e-01 5.00000000e-01\n",
            "  5.00000000e-01 5.00000000e-01 5.00000000e-01 5.00000000e-01\n",
            "  5.00000000e-01 5.00000000e-01 5.00000000e-01 5.00000000e-01\n",
            "  5.00000000e-01 5.00000000e-01 5.00000000e-01 5.00000000e-01\n",
            "  5.00000000e-01 5.00000000e-01 5.00000000e-01 5.00000000e-01\n",
            "  5.00000000e-01 5.00000000e-01 5.00000000e-01 5.00000000e-01\n",
            "  5.00000000e-01 5.00000000e-01 5.00000000e-01 5.00000000e-01\n",
            "  5.00000000e-01 5.00000000e-01 5.00000000e-01 5.00000000e-01\n",
            "  1.18526375e-16 3.46224876e-12 3.46224876e-12 2.23624900e-13\n",
            "  1.54537533e-13 2.79228161e-19 9.70907537e-17 1.10636162e-14\n",
            "  1.54537533e-13 1.32118912e-14 7.69081134e-16 7.41994378e-17\n",
            "  4.16347252e-17 1.52533906e-15 5.34464054e-10 2.24136439e-13\n",
            "  3.46224876e-12 1.35617191e-15 9.70907537e-17 2.38715036e-12\n",
            "  1.03642406e-15 1.03642406e-15 1.03642406e-15 1.03642406e-15\n",
            "  7.10420149e-17 2.32047137e-13 1.03642406e-15 6.51150510e-19\n",
            "  1.18526375e-16 1.44768595e-14 4.07055639e-11 5.29390659e-19\n",
            "  2.38715036e-12 2.23624900e-13 2.63516598e-12 1.44768595e-14\n",
            "  4.97627219e-19 1.12463036e-15 1.48298016e-23 7.97444662e-09\n",
            "  2.38715036e-12 1.44768595e-14 1.44768595e-14 1.96353571e-13\n",
            "  1.35617191e-15 1.65558649e-15 1.76730493e-14 3.56173684e-11\n",
            "  6.95089935e-18 3.32598412e-22 1.35617191e-15 2.38715036e-12\n",
            "  2.63689928e-13 1.10330402e-16 1.11033847e-17 1.03642406e-15\n",
            "  1.76730493e-14 1.54537533e-13 1.65558649e-15 1.76730493e-14\n",
            "  4.07055639e-11 7.89355721e-17 9.92320910e-16 6.51150510e-19\n",
            "  1.18526375e-16 6.95089935e-18 6.09988673e-20 1.54537533e-13\n",
            "  1.03642406e-15 1.44768595e-14 6.95089935e-18 8.52504178e-17\n",
            "  1.03642406e-15 4.86959736e-18 2.63516598e-12 6.95089935e-18\n",
            "  7.89355721e-17 4.66170205e-20 7.94911012e-19 2.46858656e-13\n",
            "  1.18526375e-16 9.92537934e-17 1.41644622e-15 1.01405898e-16\n",
            "  5.61187257e-10 5.19617830e-10 2.25601383e-13 3.05895970e-23\n",
            "  2.40923451e-22 1.41644622e-15 1.16338316e-07 2.11201295e-13\n",
            "  2.25601383e-13 1.41644622e-15 2.11201295e-13 1.51202755e-14\n",
            "  3.26990160e-12 8.10869859e-19 3.48258713e-11 5.93848949e-10]\n",
            " [9.55451086e-12 7.70821701e-12 5.44554516e-13 4.25851533e-14\n",
            "  8.63135617e-12 7.70821701e-12 7.70821701e-12 3.13717529e-15\n",
            "  5.86674729e-13 7.70821701e-12 4.97251909e-14 4.25851533e-14\n",
            "  1.22177605e-10 3.13717529e-15 5.44554516e-13 4.97251909e-14\n",
            "  8.63135617e-12 5.44554516e-13 4.25851533e-14 7.70821701e-12\n",
            "  4.25851533e-14 7.70821701e-12 3.13717529e-15 7.70821701e-12\n",
            "  4.58790305e-14 4.25851533e-14 7.27196712e-13 2.45332812e-16\n",
            "  2.41349692e-17 9.90810212e-21 7.27196712e-13 3.13717529e-15\n",
            "  3.13717529e-15 3.84504946e-15 3.13717529e-15 7.70821701e-12\n",
            "  7.70821701e-12 3.13717529e-15 3.33023642e-15 3.13717529e-15\n",
            "  1.41336085e-18 2.11034982e-17 7.70821701e-12 1.78676343e-09\n",
            "  1.22177605e-10 7.70821701e-12 4.97251909e-14 3.36240880e-15\n",
            "  1.22177605e-10 4.97251909e-14 9.00061484e-12 5.44554516e-13\n",
            "  6.22778573e-13 7.70821701e-12 4.97251909e-14 3.13717529e-15\n",
            "  4.01163982e-14 4.97251909e-14 6.29773281e-13 3.13717529e-15\n",
            "  4.97251909e-14 4.97251909e-14 5.44554516e-13 7.27196712e-13\n",
            "  3.13717529e-15 2.53095405e-15 7.96373520e-12 1.12727371e-10\n",
            "  4.97251909e-14 1.80732479e-17 3.13717529e-15 4.97251909e-14\n",
            "  6.74987747e-13 5.44554516e-13 6.22778573e-13 9.87123148e-12\n",
            "  3.13717529e-15 7.70821701e-12 7.70821701e-12 1.78676343e-09\n",
            "  1.22177605e-10 1.22177605e-10 7.70821701e-12 4.86313425e-13\n",
            "  4.86313425e-13 4.18937588e-15 1.78676343e-09 4.97251909e-14\n",
            "  7.70821701e-12 1.80732479e-17 7.70821701e-12 7.70821701e-12\n",
            "  1.24871531e-17 4.01163982e-14 5.27852692e-14 7.70821701e-12\n",
            "  6.74987747e-13 1.10315191e-11 3.13717529e-15 5.44554516e-13\n",
            "  1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
            "  1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
            "  1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
            "  1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
            "  1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
            "  1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
            "  1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
            "  1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
            "  1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
            "  1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
            "  1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
            "  1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
            "  1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
            "  1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
            "  1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
            "  1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
            "  1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
            "  1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
            "  1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
            "  1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
            "  1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
            "  1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
            "  1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
            "  1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
            "  1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00]]\n"
          ]
        }
      ],
      "source": [
        "print(NTBCwithAutomaticParameterSetting())"
      ],
      "id": "BIoXiu-kpCfs"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Traditional Naive Bayes Classifier"
      ],
      "metadata": {
        "id": "9r2td0CatcGz"
      },
      "id": "9r2td0CatcGz"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tQPEMxKMpCft"
      },
      "outputs": [],
      "source": [
        "# Implementing Multinomial Naive Bayes from scratch\n",
        "class MultinomialNaiveBayes:\n",
        "    \n",
        "    def __init__(self):\n",
        "        # count is a dictionary which stores several dictionaries corresponding to each news category\n",
        "        # each value in the subdictionary represents the freq of the key corresponding to that news category \n",
        "        self.count = {}\n",
        "        # classes represents the different news categories\n",
        "        self.classes = None\n",
        "    \n",
        "    def fit(self,X_train,Y_train):\n",
        "        # This can take some time to complete       \n",
        "        self.classes = set(Y_train)\n",
        "        for class_ in self.classes:\n",
        "            self.count[class_] = {}\n",
        "            for i in range(len(X_train[0])):\n",
        "                self.count[class_][i] = 0\n",
        "            self.count[class_]['total'] = 0\n",
        "            self.count[class_]['total_points'] = 0\n",
        "        self.count['total_points'] = len(X_train)\n",
        "        \n",
        "        for i in range(len(X_train)):\n",
        "            for j in range(len(X_train[0])):\n",
        "                self.count[Y_train[i]][j]+=X_train[i][j]\n",
        "                self.count[Y_train[i]]['total']+=X_train[i][j]\n",
        "            self.count[Y_train[i]]['total_points']+=1\n",
        "    \n",
        "    def __probability(self,test_point,class_):\n",
        "        \n",
        "        log_prob = np.log(self.count[class_]['total_points']) - np.log(self.count['total_points'])\n",
        "        total_words = len(test_point)\n",
        "        for i in range(len(test_point)):\n",
        "            current_word_prob = test_point[i]*(np.log(self.count[class_][i]+1)-np.log(self.count[class_]['total']+total_words))\n",
        "            log_prob += current_word_prob\n",
        "        \n",
        "        return log_prob\n",
        "    \n",
        "    \n",
        "    def __predictSinglePoint(self,test_point):\n",
        "        \n",
        "        best_class = None\n",
        "        best_prob = None\n",
        "        first_run = True\n",
        "        \n",
        "        for class_ in self.classes:\n",
        "            log_probability_current_class = self.__probability(test_point,class_)\n",
        "            if (first_run) or (log_probability_current_class > best_prob) :\n",
        "                best_class = class_\n",
        "                best_prob = log_probability_current_class\n",
        "                first_run = False\n",
        "                \n",
        "        return best_class\n",
        "        \n",
        "  \n",
        "    def predict(self,X_test):\n",
        "        # This can take some time to complete\n",
        "        Y_pred = [] \n",
        "        for i in range(len(X_test)):\n",
        "        # print(i) # Uncomment to see progress\n",
        "            Y_pred.append( self.__predictSinglePoint(X_test[i]) )\n",
        "        \n",
        "        return Y_pred\n",
        "    \n",
        "    def score(self,Y_pred,Y_true):\n",
        "        # returns the mean accuracy\n",
        "        count = 0\n",
        "        for i in range(len(Y_pred)):\n",
        "            if Y_pred[i] == Y_true[i]:\n",
        "                count+=1\n",
        "        return count/len(Y_pred)"
      ],
      "id": "tQPEMxKMpCft"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l9D2Z0vupCft",
        "outputId": "8864b4a7-3eea-4127-912f-127b3aaac4bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Our score on testing data : 0.605\n",
            "Classification report for testing data :-\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         rec       0.60      0.62      0.61       100\n",
            "        talk       0.61      0.59      0.60       100\n",
            "\n",
            "    accuracy                           0.60       200\n",
            "   macro avg       0.61      0.60      0.60       200\n",
            "weighted avg       0.61      0.60      0.60       200\n",
            "\n"
          ]
        }
      ],
      "source": [
        "clf2 = MultinomialNaiveBayes()\n",
        "clf2.fit(X_train,Y_Train)\n",
        "Y_test_pred = clf2.predict(X_test)\n",
        "our_score_test = clf2.score(Y_test_pred,Y_Test)  \n",
        "print(\"Our score on testing data :\",our_score_test)\n",
        "print(\"Classification report for testing data :-\")\n",
        "print(classification_report(Y_Test, Y_test_pred))"
      ],
      "id": "l9D2Z0vupCft"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}